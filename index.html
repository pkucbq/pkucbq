<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- saved from url=(0031)http://cfcs.pku.edu.cn/baoquan/ -->
<html><head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-JN0ZL4NGD9"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'G-JN0ZL4NGD9');
  </script>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="generator" content="HTML Tidy for Linux (vers 25 March 2009), see www.w3.org">
  
  <meta name="author" content="Baoquan Chen">
  <meta name="description" content="Baoquan&#39;s Homepage">
  <meta name="robots" content="index, follow, noarchive">
  <meta name="googlebot" content="noarchive">
  <style type="text/css">
A.applink:hover {border: 2px dotted #DCE6F4;padding:2px;background-color:#ffff00;color:green;text-decoration:none}
        A.applink       {border: 2px dotted #DCE6F4;padding:2px;color:#2F5BFF;background:transparent;text-decoration:none}
        A.info          {color:#2F5BFF;background:transparent;text-decoration:none}
        A.info:hover    {color:green;background:transparent;text-decoration:underline}
  </style>

  <title>Baoquan Chen (陈宝权), Peking University</title>
    <script type="text/javascript" async="" src="./figure/ga.js.下载"></script><script type="text/javascript" async="" src="./figure/ga.js(1).下载"></script><script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-32399596-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</head>

<body background="./figure/welcomebg.gif" link="#253FB2">

  <table align="center" width="1024" summary="">
    <tbody><tr>
      <td><img src="./figure/Baoquan_portrait.jpg" width="300" alt="Baoquan&#39;s portrait"><br>
      </td>

      <td>
        <h1>Baoquan Chen (陈宝权) <a href="The Chop.html"><img src="./figure/chop_cbq_s.jpg" width="40" alt=""></a></h1>

<h3 style="font:&#39;Times New Roman&#39;, Times, serif">Associate Dean of <a href="https://www.cis.pku.edu.cn/">the School of Artificial Intelligence</a>, <a href="http://www.pku.edu.cn/">Peking University</a>.</h3>

<!-- <h3 style="font:&#39;Times New Roman&#39;, Times, serif">北京大学智能学院，副院长</h3> -->

<p><br>
  <font size="-1">
    Past positions: <br>
    Executive director of the <a href="https://cfcs.pku.edu.cn/">Center on Frontiers of Computing Studies</a>, <a href="https://www.pku.edu.cn/">PKU</a><br>
    Founding Director of the <a href="http://irc.cs.sdu.edu.cn/">Interdisciplinary Research Center</a>, <a href="http://www.sdu.edu.cn/">SDU</a><br>
    Founding Director of the <a href="http://english.siat.cas.cn/">Visual Computing Research Center</a>, <a href="http://english.siat.cas.cn/">SIAT</a><br>
    Deputy Director of the <a href="http://english.siat.cas.cn/">Institute of Advanced Computing and Digital Engineering (IACDE)</a>
  </font>
</p>

<!-- <p><br>
<font size="-1">Formerly Founding Director of the <a href="http://irc.cs.sdu.edu.cn/">Interdisciplinary Research Center</a>，<a href="http://www.sdu.edu.cn/">SDU</a><br>
Formerly Founding Director of the <a href="http://english.siat.cas.cn/">Visual Computing Research Center</a>，<a href="http://english.siat.cas.cn/">SIAT</a><br>
Formerly Deputy Director of the <a href="http://szs.siat.ac.cn/">Institute of Advanced Computing and Digital Engineering (IACDE)</a></font></p> -->

<p>Email: baoquan At pku.edu.cn <a href="http://weibo.com/baoquanchen" target="blank_"><img height="32" src="./figure/sina-weibo.png"></a>: <a href="http://weibo.com/baoquanchen" target="blank_">http://weibo.com/baoquanchen</a><br>
Address: Rm 2216, Li Ke Building #2, Peking University, 5 Yiheyuan Road, Haidian District, Beijing 100871, P.R. China</p>

<p><b>Open positions available (researchers, PostDocs, graduate students, interns). Contact me for details.</b></p>

<p><b>Research Interests</b><br>
<u>General Interests</u>: Computer Graphics and Visualization<br>
<u>Specific Interests</u>: Large Environment Acquisition, Accelerated Rendering, Antialiasing, Volume Visualization<br>
<u>Applications</u>: Scientific &amp; Biomedical Visualization, Digital Architecture Design, Art and Entertainment</p>

<p><b>Portrait</b><br>
<a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-08/20210807171127844317.jpg">Full</a>,&nbsp;<a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-08/20210807171132313456.jpg">face</a></p>


<!--h3 style="font:&#39;Times New Roman&#39;, Times, serif">Dean of the <a href="http://www.cs.sdu.edu.cn/default.do">School of Computer Science and Technology</a> and <a href="http://www.cs.sdu.edu.cn/default.do"></a><a href="http://www.sc.sdu.edu.cn/default.do">School of Software Engineering</a> , <a href="http://www.sdu.edu.cn/">Shandong University</a></h3>
        <p><font size="-1"><br>
		Founding Director of the <a href="http://irc.cs.sdu.edu.cn/">Interdisciplinary Research Center</a>，<a href="http://www.sdu.edu.cn/">SDU</a><br>
		
        Formerly Founding Director of the <a href="http://vcc.siat.ac.cn/">Visual
        Computing Research Center</a>，<a href="http://english.siat.cas.cn/">SIAT</a><br>
          Formerly Deputy Director of the <a href="http://szs.siat.ac.cn/">Institute of Advanced Computing
        and Digital Engineering (IACDE)</a></font></p>
<p></p>
        <p>Email: baoquan At sdu.edu.cn
		<a href="http://weibo.com/baoquanchen" target="blank_"><img src="images/sina-weibo.png" height="32"></a>: <a href="http://weibo.com/baoquanchen" target="blank_">http://weibo.com/baoquanchen</a>
		<br>
        Address: No.1500, Shunhua Road, Jinan, Shandong Province, P.R. China </p>
        <p><b>Open positions available (researchers, PostDocs, graduate students, interns). Contact me for details.</b></p>

		<p><b>Looking for PostDocs! This is a joint position between <a href="http://www.cs.tau.ac.il/~dcor/index.html">Daniel Cohen-Or</a> and me, under a China-Israel joint grant. To apply, please email us both together.</b></p>
		
		
        <p><b>Research Interests</b><br>
        <u>General Interests</u>: Computer Graphics and
        Visualization<br>
        <u>Specific Interests</u>: Large Environment Acquisition,
        Accelerated Rendering, Antialiasing, Volume
        Visualization<br>
        <u>Applications</u>: Scientific &amp; Biomedical
        Visualization, Digital Architecture Design, Art and
        Entertainment<br></p-->

      </td>
    </tr>
  </tbody></table>

  <table align="center" width="1024" border="2" summary="">
    <tbody><tr>
      <td><i><font size="+2" color="#5F3F0E">News</font></i></td>

      <td>
        <ul>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">4.26: talk by Dr. </span><a href="https://research.cs.washington.edu/istc/lfb/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Liefeng Bo</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Alibaba,&nbsp;<i>人物视频生成新范式(A New Paradigm for Human Video Generation)</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">1.8: talk by </span><a href="https://www.cs.columbia.edu/~rundi/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Rundi Wu</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Columbia University,&nbsp;<i>ReconFusion: 3D Reconstruction with Diffusion Priors</i>.</span>
          </li>
          <!-- <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">12.25: talk by </span><a href="https://justimyhxu.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Yinghao Xu</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Stanford University,&nbsp;<i>Large reconstruction model for 3D reconstruction and generation</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">11.27: talk by </span><a href="https://lingjie0206.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Lingjie Liu</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from the University of Pennsylvania,&nbsp;<i>From 3D Reconstruction to 3D Generation</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">11.10: talk by </span><a href="https://zhenxuan00.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Chongxuan Li</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Renmin University of China,&nbsp;<i>Diffusion Model and Visual Content Generation</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">10.13: talk by </span><a href="https://yangzzzy.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Yin Yang</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from the University of Utah,&nbsp;<i>Linearly and Nonlienarly Reduced Models for Fast Solid Simulation</i>.</span>
          </li> -->
          <!-- <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">9.25: talk by </span><a href="https://kuiwuchn.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Kui Wu</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Tencent America,&nbsp;<i>A general sag-free initialization for deformable simulations</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">9.5: talk by Prof. </span><a href="https://www.cs.sfu.ca/~haoz/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Hao (Richard) Zhang</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Simon Fraser University,&nbsp;<i>An Evolution of Learning Neural Implicit Representations for 3D Shapes</i>.</span>
          </li> -->
          <!-- <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">8.22: talk by </span><a href="https://www.yf.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Fisher Yu</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from ETH Zürich,&nbsp;<i>Scaling Up 4D Scene Understanding with Less Hassle</i>.</span>
          </li> -->
          <!-- <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">7.31: talk by Prof. </span><a href="https://www.cse.wustl.edu/~taoju/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Tao Ju</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Washington University,&nbsp;<i>Interactive Modeling with Implicit Functions</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">7.27: talk by </span><a href="https://vlg.inf.ethz.ch" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Siyu Tang</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from ETH Zürich,&nbsp;<i>Reconstruction and synthesis of 3D humans in 3D scenes</i>.</span>
          </li>
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">7.25: talk by </span><a href="https://gaoxifeng.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Xifeng Gao</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Tencent,&nbsp;<i>Robust Low-Poly Meshing</i>.</span>
          </li> -->

          <!--
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">5.19: talk by </span><a href="https://cqf.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Qifeng Chen</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from HKUST,&nbsp;<i>Towards Photorealistic Video and 3D Synthesis with Foundation Models</i>.</span>
          </li>

          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">5.12: talk by </span><a href="https://xiuyuliang.cn/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Yuliang Xiu</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Max Planck Institute for Intelligent Systems,&nbsp;<i>Towards large-scale human digitization from in-the-wild pixels, Explicit or Implicit?</i>.</span>
          </li>

          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">4.28: talk by </span><a href="https://peterchencyc.com/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Peter Yichen Chen</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from MIT CSAIL,&nbsp;<i>Fast and Accurate PDE Solvers via Neural Fields</i>.</span>
          </li>

          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">4.25: talk by </span><a href="https://www.cs.toronto.edu/~jungao/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Jun Gao</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from the University of Toronto,&nbsp;<i>Machine Learning for 3D Content Creation</i>.</span>
          </li>

          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">4.14: talk by </span><a href="https://people.inf.ethz.ch/~linyang/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Lingchen Yang</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from ETH Zurich,&nbsp;<i>Implicit Neural Representations for Actuated Soft Bodies and High-fidelity Hair</i>.</span>
          </li>

          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">4.14: talk by </span><a href="https://www.cs.huji.ac.il/~danix/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Prof. Daniel Lischinski</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from the Hebrew University of Jerusalem,&nbsp;<i>Controllable Generative Models</i>.</span>
          </li>

          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">4.14: talk by </span><a href="https://danielcohenor.com/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Prof. Daniel Cohen-Or</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from the Tel-Aviv University,&nbsp;<i>Textual Inversion</i>.</span>
          </li>

			 <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">4.7: talk by </span><a href="https://www.cse.cuhk.edu.hk/~qdou/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Qi Dou</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from the Chinese University of Hong Kong,&nbsp;<i>From Videos to 4D Worlds and Beyond</i>.</span>
          </li>
			
			<li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">4.7: talk by </span><a href="https://people.eecs.berkeley.edu/~kanazawa/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Angjoo Kanazawa</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from the University of California, Berkeley,&nbsp;<i>Decoupling Human and Camera Motion from Videos in the Wild</i>.</span>
          </li>
			
			<li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">3.31: talk by </span><a href="https://people.iiis.tsinghua.edu.cn/~taodu/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Tao Du</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Tsinghua University,&nbsp;<i>Computational Design of Physical Systems with Solid-Fluid Coupling</i>.</span>
          </li> -->
			
<!--
			<li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">12.3: talk by &nbsp;</span><a href="https://www.cs.utexas.edu/~grauman/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Kristen Grauman</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from University of Texas at Austin,&nbsp;<i>Sounds and space for audio-visual learning</i>.</span>
          </li>
			
			<li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">10.21: talk by &nbsp;</span><a href="http://www.cs.toronto.edu/~jungao/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Gao Jun</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from University of Toronto,&nbsp;<i>Towards Generative Modeling of 3D Objects Learned from Images</i>.</span>
          </li>
			
			<li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">10.7: talk by Dr.&nbsp;</span><a href="https://cseweb.ucsd.edu/~zex014/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Zexiang Xu</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Adobe Research,&nbsp;<i>Neural Scene Representations and Applications</i>.</span>
          </li>
			
          <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">9.23: talk by Dr.&nbsp;</span><a href="https://www.cs.cornell.edu/~hadarelor/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Hadar Averbuch-Elor</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Cornell Tech,&nbsp;<i>Deep into 3DV: Pushing the Boundaries of 3D Vision</i>.</span>
          </li>
                      <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">8.26: talk by&nbsp;</span><a href="https://www.purvigoel.com//" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Purvi Goel</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Stanford University,&nbsp;<i>Unified Many Worlds Browsing of Arbitrary Physics-Based Animations</i>.</span>
</li>
-->
<!--
                      <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">7.22: talk by Dr.&nbsp;</span><a href="http://dannykaufman.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Danny Kaufman</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Adobe Research,&nbsp;<i>Incremental Potential Contact: Simulating Dynamics with Correctness and Interactivity</i>.</span>
</li>
-->
<!--
                      <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">7.15: talk by Dr. </span><a href="http://www.connellybarnes.com/work/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Connelly Barnes</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Adobe and </span><a href="https://www.cs.princeton.edu/~yutingy/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Yuting Yang</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Princeton University,&nbsp;<i>Aδ: Autodiff for Discontinuous Programs – Applied to Shaders</i>.</span>
</li>
                      <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">7.1: talk by&nbsp;</span><a href="https://sites.google.com/site/jsmerel/home/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Josh Merel</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Reality Labs,&nbsp;<i>Neural motor skills for simulated and robotic agents</i>.</span>
</li>
-->
                      <!-- <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">6.3: talk by&nbsp;</span><a href="https://zhengqili.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Zhengqi Li</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Google Research,&nbsp;<i>Beyond Novel View</i>.</span>
</li>
                      <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">5.27: talk by&nbsp;</span><a href="http://crl.ethz.ch/people/coros/index.html" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Stelian Coros</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from ETH Zurich,&nbsp;<i>Physics-based modeling and the quest for intelligent robots</i>.</span>
</li>
                      <li><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">5.13: talk by&nbsp;</span><a href="https://yotamnitzan.github.io/" style="font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">Yotam Nitzan</a><span style="color: rgb(0, 0, 0); font-family: &quot;Microsoft YaHei&quot;; font-size: medium;">&nbsp;from Tel-Aviv Univeristy,&nbsp;<i>MyStyle: A Personalized Generative Prior</i>.</span>
</li> -->
                      <li><a href="http://vcl.pku.edu.cn/activities.html">More</a>
</li>
                   
        </ul>
      </td>
    </tr>

    <tr>
      <td><i><font size="+2" color="#5F3F0E">Research</font></i></td>

      <td>
        <table summary="">
          <tbody><tr>
            <td>
             
<p>
ORCID：0000-0003-4702-036X<br>
<a href="Projects&Publications.html"><font size="+2" color="#5F3F0E">Full list of publications</font></a>
      </p><p>Recent publications</p>

<ul>
  <li>Weiyu Li, Xuelin Chen, Peizhuo Li, Olga Sorkine-Hornung, Baoquan Chen. <strong>Example-based Motion Synthesis via Generative Motion Matching.</strong> ACM Transactions on Graphics (Proceedings of SIGGRAPH)&nbsp;2023.</li>
  <li>Yingda Yin, Yang Wang, He Wang, Baoquan Chen. <strong>A Laplace-inspired Distribution on SO(3) for Probabilistic Rotation Estimation.</strong> ICLR 2023.</li>
	<li>Tenglong Ao, Qingzhe Gao, Yuke Lou, Baoquan Chen, Libin Liu.&nbsp;<strong>Rhythmic Gesticulator: Rhythm-Aware Co-Speech Gesture Synthesis with Hierarchical Neural Embeddings</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia)&nbsp;2022 (<strong>Best Paper Award</strong>).</span></li>
	<li>Heyuan Yao, Zhenhua Song, Baoquan Chen, Libin Liu.&nbsp;<strong>ControlVAE: Model-Based Learning of Generative Controllers for Physics-Based Characters</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia)&nbsp;2022.</span></li>
	<li>Jingrui Xing, Liangwang Ruan, Bin Wang, Bo Zhu, Baoquan Chen.&nbsp;<strong>Position-based Surface Tension Flow</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia)&nbsp;2022.</span></li>
	<li>Xuwen Chen, Xingyu Ni, Bo Zhu, Bin Wang, Baoquan Chen.&nbsp;<strong>Simulation and optimization of magnetoelastic thin shells</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH)&nbsp;2022.</span></li>
	<li>Yujie Wang, Praneeth Chakravarthula, Qi Sun, Baoquan Chen.&nbsp;<strong>Joint neural phase retrieval and compression for energy- and computation-efficient holography on the edge</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH)&nbsp;2022 (<strong>Best Paper Honorable Mention</strong>).</span></li>
<!--
  <li>Yunzhe Liu, Rinon Gal, Amit H. Bermano, Baoquan Chen, Daniel Cohen-Or.&nbsp;<strong>Self-Conditioned GANs for Image Editing</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM SIGGRAPH 2022 Conference Proceedings&nbsp;2022.</span></li>
	<li>Yingda Yin, Yingcheng Cai, He Wang, Baoquan Chen.&nbsp;<strong>FisherMatch: Semi-Supervised Rotation Regression via Entropy-based Filtering</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">CVPR 2022.</span></li>
	<li>Kai Ye, Siyan Dong, Qingnan Fan, He Wang, Li Yi, Fei Xia, Jue Wang, Baoquan Chen.&nbsp;<strong>Multi-Robot Active Mapping via Neural Bipartite Graph Matching</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">CVPR 2022.</span></li>

	<li>Yuchen Sun, Xingyu Ni, Bo Zhu, Bin Wang, Baoquan Chen.&nbsp;<strong>A Material Point Method for Nonlinearly Magnetized Materials</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia)&nbsp;2021.</span></li>
	<li>Jing Li, Tiantian Liu, Ladislav Kavan, Baoquan Chen.&nbsp;<strong>Interactive Cutting and Tearing in Projective Dynamics with Progressive Cholesky Updates</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia)&nbsp;2021.</span></li>
	<li>Hongda Jiang, Marc Christie, Xi Wang, Bin Wang, Baoquan Chen.&nbsp;<strong>Camera Keyframing with Style and Control</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia) 2021.</span></li>
	<li>Jian Liu, Shiqing Xin, Xifeng Gao, Kaihang Gao, Kai Xu, Baoquan Chen, Changhe Tu.&nbsp;<strong>Computational Object-Wrapping Rope Nets</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics 2021.</span></li>
	<li>Liangwang Ruan, Jinyuan Liu, Bo Zhu, Shinjiro Sueda, Bin Wang, Baoquan Chen.&nbsp;<strong>Solid-Fluid Interaction with Surface-Tension-Dominant Contact.</strong>&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH) 2021.</span></li>
-->
</ul>

<p>Representative publications</p>

<ul>
	<li>Yangyan Li, Rui Bu, Mingchao Sun, Wei Wu, Xinhan&nbsp;Di, Baoquan Chen.&nbsp;<strong>PointCNN: Convolution on x-transformed points</strong><span style="color: rgb(0, 0, 0); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, &quot;Source Han Sans SC&quot;, &quot;Noto Sans CJK SC&quot;, &quot;WenQuanYi Micro Hei&quot;, sans-serif; font-size: 13.3333px; white-space: pre-wrap; caret-color: rgb(30, 111, 255);">. </span>Proceedings of&nbsp;Advances in Neural Information Processing Systems (NeurIPS) 2018.</li>
	<li>Lin Lu, Andrei Sharf, Haisen&nbsp;Zhao, Yuan Wei, Qingnan Fan, Xuelin Chen, Yann Savoye,&nbsp;Changhe Tu,&nbsp;Daniel Cohen-Or,&nbsp;Baoquan Chen.&nbsp;<strong>Build-to-last: Strength to weight 3D printed objects</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH)&nbsp;2014.</span></li>
	<li>Liangliang Nan, Andrei Sharf,&nbsp;Hao Zhang,&nbsp;Daniel Cohen-Or,&nbsp;Baoquan Chen.&nbsp;<strong>Smartboxes for interactive urban reconstruction</strong>.&nbsp;<span style="color: rgb(34, 34, 34); font-family: Arial, sans-serif;">ACM Transactions on Graphics (Proceedings of SIGGRAPH)&nbsp;2010.</span></li>
	<li>Hong Zhou, Xiaoru Yuan,&nbsp;Huamin Qu,&nbsp;Weiwei Cui,&nbsp;Baoquan Chen.<strong>&nbsp;Visual clustering in parallel coordinates</strong>.&nbsp;Computer Graphics Forum&nbsp;2008.</li>
</ul>

<p>中文文章​</p>

<ul>
  <li>2022年第12期 <a href="https://dl.ccf.org.cn/article/articleDetail.html?type=xhtx_thesis&_ack=1&id=6262370807842816">计算机图形学将是未来智能的入口</a></li>
	<li>2021年第7期 <a href="https://jszx5.pku.edu.cn/pub/baoquan/docs/2024-05/20240506232736328266.pdf">从数字城市到数字孪生城市</a></li>
	<li>2020年第7期&nbsp;<a href="https://jszx5.pku.edu.cn/pub/baoquan/docs/2024-05/20240506232759708333.pdf">面向新冠疫情的数据可视化分析</a></li>
	<li>2019年第6期&nbsp;<a href="https://jszx5.pku.edu.cn/pub/baoquan/docs/2024-05/20240506232817921426.pdf">赋能机器人——计算机学科的机遇与使命</a></li>
	<li>2016年第8期&nbsp;<a href="https://jszx5.pku.edu.cn/pub/baoquan/docs/2024-05/20240506232833395547.pdf">大数据时代的城市计算</a></li>
	<li>2016年第8期&nbsp;<a href="https://jszx5.pku.edu.cn/pub/baoquan/docs/2024-05/20240506232852097605.pdf">大规模城市场景建模与理解</a></li>
	<li>2012年第19期&nbsp;<a href="https://jszx5.pku.edu.cn/pub/baoquan/docs/2024-05/20240506232952499890.pdf">基于三维视频融合的监控分析系统</a>&nbsp;（《中国公共安全（综合版）》）</li>
	<li>2009年第7期&nbsp;<a href="https://jszx5.pku.edu.cn/pub/baoquan/docs/2024-05/20240506232712483163.pdf">数字化城市（第一人生）</a></li>
</ul>

<p>以上文章除特别标明，均发表于《中国计算机学会通讯》</p>

<p>Media coverage</p>

<ul>
  <li>
    科技冬奥 【<a href="https://space.bilibili.com/28217340/channel/collectiondetail?sid=812012">合集</a>】
    <ul>
      <li><img height="16" src="./figure/video.png" ><a href="https://jszx5.pku.edu.cn/pub/baoquan/docs/2024-03/20240309122150924435.mp4">交互式观赛技术</a></li>
      <li>2022.3.9: 央视新闻直播间报道北大陈宝权团队科技冬奥项目助力北京冬残奥会：<a href="https://content-static.cctvnews.cctv.com/snow-book/index.html?toc_style_id=feeds_default&amp;share_to=wechat&amp;item_id=7575820793624626086&amp;track_id=24783BE6-23F1-466C-94BF-9BFA5759E497_668505736232">展示给观众接近360度旋转“自由视点”</a></li>
      <li>2021.1.11: “<a href="https://m.bjnews.com.cn/detail/164186887914571.html">北京大学 | 把电影特效带进赛事转播，实现交互式多维度观赛</a>”</li>
	    <li>2021.12.31: <img height="16" src="./figure/video.png" >“<a href="https://www.bilibili.com/video/BV16M4y1F7UT/?share_source=copy_web&vd_source=11203983f1ad5986958c2f35a08a12ce">2022科学跨年之夜</a>”</li>
      <li>2021.11.9: 科技冬奥：<a href="http://www.china.org.cn/business/2021-11/09/content_77861903.htm">“交互式自由视点VR观赛”五棵松体育馆测试</a></li>
	    <li>2021.10.27: 科技日报“<a href="http://digitalpaper.stdaily.com/http_www.kjrb.com/kjrb/html/2021-10/27/content_523909.htm">冰雪运动，激情飞扬</a>”</li>
      <li>2021.7.19: 科技日报“<a href="http://digitalpaper.stdaily.com/http_www.kjrb.com/kjrb/html/2021-07/19/content_472010.htm">中国方案提升冬奥会筹办水平</a>”</li>
      <li>2021.6.7: <img height="16" src="./figure/video.png" >北京电视台《冬奥纪实》节目采访陈宝权教授介绍其团队科研成果“<a href="https://m.btime.com/item/218g4ps94j936qsquqmphdq02mg">科技冬奥，交互观赛</a>”</li>
      <li>2021.4.6: 科技日报“<a href="http://digitalpaper.stdaily.com/http_www.kjrb.com/kjrb/html/2021-04/06/content_465420.htm">场外看冬奥 自由交互技术让你‘身临其境’</a>”</li>
    </ul>
  </li>

	<li>2021.12.5:&nbsp;当选2021年度<a href="https://mp.weixin.qq.com/s/wKBIuotcQaAtM3k9WjQm2A">中国图象图形学学会会士</a></li>
	<li>2021.9.11: “<a href="https://mp.weixin.qq.com/s/6UYyrhgxZrzOMPmIuG1tEQ">不编程，拖拖鼠标图表自己动起来，新研究获ACM CHI最佳论文荣誉提名</a>”（<a href="http://www.yunhaiwang.net/EuroVis2020/canis/paper.pdf">文章链接</a>）</li>
	<li>2021.7.23: “<a href="https://mp.weixin.qq.com/s/VinRG0nYoUdkE4wA8_cRnQ">AI救援河南洪灾</a>”</li>
  <li>2021.7.15: “<a href="https://mp.weixin.qq.com/s/2_W_vSmayVlsXEbw35gWyw">对话John Hopcroft教授：新国际环境下的高等教育与学术人生</a>”</li>
  <li>2021.5.9: “<a href="https://mp.weixin.qq.com/s/u3eLDjtyGV0aVqEm6KXo6w">模拟水面表面张力，效果自然、真实，北大图灵班研究入选SIGGRAPH</a>”（<a href="https://lwruan.com/publication/waterstrider/">文章链接</a>）</li>
	<li>2020.5.27: “<a href="https://mp.weixin.qq.com/s/uU1-DwHnU4pPMLtQZNQyVQ">北大图灵班本科生带来动画CG福音，「最懂骨骼的卷积网络」</a>”（<a href="https://deepmotionediting.github.io/retargeting">文章链接</a>）</li>
	<li>2020.2.11: “<a href="https://mp.weixin.qq.com/s/GoExay4zzZQcFL1T0f2OfA">面向新冠疫情的数据可视化分析与模拟预测</a>”（<a href="https://arxiv.org/abs/2002.07096">文章链接</a>）</li>
	<li>2016.12.10: <img height="16" src="./figure/video.png">“<a href="https://jszx5.pku.edu.cn/pub/baoquan/docs/2024-03/20240309122013374301.mp4">归去来兮：回到国内做学术的个人体会与观察”</a></li>
  <li>2014.10.25 “<a href="https://www.ituring.com.cn/article/127792">陈宝权教授访谈图灵奖获得者Ivan Sutherland</a>”</li>
  <li>2013.4.10: <img height="16" src="./figure/video.png" >中央电视台《走进科学》专题报道陈宝权教授及其团队科研成果—“<a href="http://tv.cctv.com/2013/04/09/VIDE1365519779747781.shtml">把城市搬进电脑</a>”</li>
	<li>2010.4.28: 晶报新闻“<a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-10/20211020150616225114.pdf">用‘阿凡达’技术‘重建’深圳</a>”</li>
</ul>

<p>Funding provided by: NSF, ARL, ONR, Microsoft (~2008), NSFC, MOST, Nvidia, etc.</p>

              <!--  <ul>
                <li><a href="research/projects_publications/index.htm"><font size="+1" color="#5F3F0E">Projects &amp;
                Publications</font></a></li>
      
</ul>      -->
 
<p></p>        
            </td>

            <td valign="bottom">&nbsp;</td>

            <td valign="bottom">&nbsp;</td>

            <td valign="bottom">&nbsp;</td>
          </tr>
        </tbody></table>
      </td>
    </tr>

    <tr>
      <td><i><font size="+2" color="#5F3F0E">Service</font></i></td>

      <td>
                      <p><font size="+0">Program committee member unless otherwise noted (not up to date):</font></p>

<ul>
	<li>SIGGRAPH (<a href="https://history.siggraph.org/conference/siggraph-2017-44th-annual-conference-on-computer-graphics-and-interactive-techniques/">2017</a>), SIGGRAPH Asia (<a href="http://sa2013.siggraph.org/">2013</a>,&nbsp;<a href="http://sa2014.siggraph.org/en/">2014</a>)</li>
	<li><a href="http://sa2014.siggraph.org/en/">SIGGRAPH Asia 2014</a>&nbsp;(conference chair)</li>
	<li>SIGGRAPH Asia steering committee (2013-)</li>
	<li><a href="http://ieeevis.org/year/2016/info/committees/scivis-steering-committee">IEEE SciVIS Steering committee</a>&nbsp;(2014-)</li>
	<li><a href="http://vis.computer.org/">IEEE Visualization</a>&nbsp;<a href="http://vis.computer.org/vis2007/">2007</a>,&nbsp;<a href="http://vis.computer.org/vis2006/">2006</a>&nbsp;(general co-chair),&nbsp;<a href="http://vis.computer.org/vis2005/">2005</a>&nbsp;(general co-chair), and&nbsp;<a href="http://vis.computer.org/vis2004/">2004</a>&nbsp;(program co-chair)</li>
	<li><a href="http://mm.cse.wustl.edu/pg07/index.php">Pacific Graphics 2007</a></li>
	<li>Symposium on Point-based Graphics&nbsp;<a href="https://graphics.ethz.ch/events/pbg/07/">2007</a>&nbsp;(program co-chair),&nbsp;<a href="https://graphics.ethz.ch/events/pbg/06/">2006</a>&nbsp;(papers co-chair),&nbsp;<a href="http://www.cs.princeton.edu/gfx/pbg05/index.html">2005</a>,&nbsp;<a href="https://graphics.ethz.ch/events/pbg/">2004</a></li>
	<li><a href="http://pma.cirad.fr/PMA06/index.htm">PMA06:The Second International Symposium on Plant growth Modeling,Simulation, Visualization and Applications</a>&nbsp;2006 (also keynote speaker)</li>
	<li><a href="http://www.eurovis.org/">Eurographics/IEEE-VGTC Symposium on Visualization</a>&nbsp;<a href="http://dcgi.felk.cvut.cz/cgg/eg07/">2007</a>,&nbsp;<a href="https://www.cg.tuwien.ac.at/events/EG06/index.php">2006</a></li>
	<li>Eurographics Workshop on Sketch-Based Interfaces and Modeling (SBIM) 2007, 2006 (<a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2006.00923.x">my report on SBIM'05</a>)</li>
	<li>International Conference on 3-D Digital Imaging and Modeling 2005</li>
	<li>Symposium on Volume Visualization and Graphics(VolVis) 2004, 2002</li>
	<li>Computer Graphics International 2005,&nbsp;<a href="http://www.ics.forth.gr/cgi2004/intro.html">2004</a></li>
	<li>IEEE Volume Graphics 2006, 2003, 2001</li>
</ul>

<p><span style="font-size: medium;">中文文章：</span></p>

<ul>
	<li>2015年第9期 <a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-11/20211102171239805155.pdf">变革中的大学计算机学科建设</a>&nbsp;(<a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-11/20211102172141930206.pdf">Daniel Cohen-Or</a>, <a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-11/20211102172147749317.pdf">James D. Foley</a>, <a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-11/20211102172151926439.pdf">张晓东</a>)</li>
	<li>2015年第1期&nbsp;<a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-11/20211102171234435043.pdf">SIGGRAPH Asia 2014</a></li>
	<li>2012年第6期&nbsp;<a href="http://cfcs.pku.edu.cn/baoquan/docs/2021-11/20211102171228278940.pdf">青年科技工作者的价值与成功</a></li>
</ul>

                </td>
    </tr>

    <tr>
      <td><i><font size="+2" color="#5F3F0E">Teaching</font></i></td>

      <td>
        <font size="+0">Classes taught (not up to date):</font>

        <ul>

                      <li><font size="+0">Computer Generated Imagery and Visual Effects, <a href="https://computergive.github.io/2018-fall/index.html">Fall 2018</a>, <a href="https://computergive.github.io/2019-spring/index.html">Spring 2019</a></font>
</li>
                      <li>Computer Graphics, Fall 2014, Fall 2015
</li>
                      <li><font size="+0">Algorithms and Data
          Structures</font></li>
                      <li><font size="+0">Commodity Graphics Hardware
          Accelerated Rendering</font></li>
                    
        </ul>
      </td>
    </tr>
  </tbody></table>

  <table align="center" width="1024" summary="">
    <tbody><tr>
      <td>
        <h2>Short Biography</h2>
      </td>
    </tr>
  
      <tr>
      <td>
                  <p><span style="color: rgb(0, 0, 0); font-family: &quot;lucida Grande&quot;, Verdana, &quot;Microsoft YaHei&quot;; font-size: medium;">陈宝权，北京大学教授，智能学院副院长。研究领域为计算机图形学、三维视觉与可视化，担任国家“973计划”“城市大数据计算理论与方法”项目首席科学家，主持国家自然科学基金重点项目、国家重点研发计划“科技冬奥”项目等。在 ACM SIGGRAPH、IEEE VIS、ACM Transactions on Graphics (TOG)、IEEE Transactions on Visualization and Graphics （TVCG） 等国际会议和期刊发表论文200余篇。现任中国图象图形学学会常务理事、CSIG三维视觉专委会主任；中国计算机学会（CCF）常务理事、计算机辅助设计与图形学专委会常务理事、大数据专委会常务委员；Computer &amp; Graphics期刊编委指导委员会成员；《中国计算机通讯》专题栏目主编；《大数据》期刊编委； IEEE VIS Papers Committee member；中国可视化与可视分析大会（ChinaVIS）指导委员会成员。多次担任计算机图形与可视化领域几乎所有重要国际会议的PC成员：IEEE VIS 2005大会主席、2004 程序委员会主席；SIGGRAPH ASIA 指导委员会成员、2014大会主席；2017年共同发起计算机图形学与混合现实研讨会（GAMES）并任指导委员会成员；2021年发起中国三维视觉大会（China3DV）并任首届会议主席（2021）。曾任第七届教育部科技委信息学部委员；ACM TOG、 IEEE TVCG 编委；中国计算机学会（CCF）青工委主任；国家自然科学基金委（NSFC）信息领域专家评审组成员；中国自动化学会理事；北京电影学院未来影像高精尖创新中心首席科学家。获美国国家科学基金会杰出青年学者奖（NSF CAREER Award 2003）、IEEE可视化国际会议最佳论文奖（2005）、中国计算机图形学大会杰出奖（2014）。入选中科院百人计划（2008）、国家杰出青年科学基金资助（2010）、教育部长江学者特聘教授（2015）、国家万人计划领军人才（2017）。2017年当选中国计算机学会会士，2020年当选 IEEE Fellow，2021年入选IEEE Visualization Academy，当选中国图象图形学学会会士。</span></p>

              </td>
    </tr>
      <tr>
      <td>
                  <p>Baoquan Chen is a Professor of <a href="http://www.pku.edu.cn/">Peking University</a>, where he is the Associate Dean of <a href="https://www.cis.pku.edu.cn/">the School of Artificial Intelligence</a>. His research interests generally lie in computer graphics, computer vision, visualization, and human-computer interaction. He has published more than 200 papers in international journals and conferences, including 40+ papers in ACM Transactions on Graphics (TOG)/SIGGRAPH/SIGGRAPH_Asia. Chen serves/served as associate editor of ACM TOG/IEEE Transactions on Visualization and Graphics (TVCG), and has served as conference steering committee member (ACM SIGGRAPH Asia, IEEE VIS), conference chair (<a href="http://sa2014.siggraph.org/en/">SIGGRAPH Asia 2014</a>, IEEE Visualization 2005), program chair (IEEE Visualization 2004), as well as program committee member of almost all conferences in the visualization and computer graphics fields for numerous times. Chen is the recipient of 2002 Microsoft Innovation Excellence Program, 2003 <a href="http://www.nsf.gov/home/crssprgm/career/start.htm">NSF CAREER</a> award, 2004 McKnight Land-Grant Professorship at the University of Minnesota (Twin Cities), 2005 <a href="http://vis.computer.org/vis2005/">IEEE Visualization Best Paper Award</a>, and 2014 Outstanding Achievement Award of Chinagraph.</p>

<p>Prior to the current post, he was dean of the School of Computer Science and Technology and the School of Software and founding director of the <a href="http://irc.cs.sdu.edu.cn/">Interdisciplinary Research Center, Shandong University</a> (2013-2018), founding director of the Visual Computing Research Center and deputy director of the Institute of Advanced Computing and Digital Engineering, Shenzhen Institute of Advanced Technology (SIAT), Chinese Academy of Sciences (2008-2013), and a faculty member at the department of Computer Science and Engineering at the University of Minnesota at Twin Cities (2000-2008). Chen received an MS in Electronic Engineering from Tsinghua University, Beijing, China, and a second MS and then PhD in Computer Science from the State University of New York at Stony Brook, New York, U.S.A. For his contribution to spatial data visualization, he was elected <a href="https://cfcs.pku.edu.cn/english/news/236888.htm">IEEE Fellow</a> in 2020. He was inducted to IEEE Visualization Academy and was elected as CSIG Fellow in 2021.</p>

<p>&nbsp;</p>

              </td>
    </tr>
  	
  </tbody></table>

  <p align="center"><img src="./figure/feather.gif" alt=""></p>
  
  <!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=10716942; 
var sc_invisible=1; 
var sc_security="0bb55d3c"; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script><script type="text/javascript" src="./figure/counter.js.下载"></script></body></html>